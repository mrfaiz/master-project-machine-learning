{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a9ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "from sklearn.metrics import f1_score\n",
    "from model_hetero import HAN\n",
    "from utils import load_data, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa634f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(logits, labels):\n",
    "    _, indices = torch.max(logits, dim=1)\n",
    "    prediction = indices.long().cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "\n",
    "    accuracy = (prediction == labels).sum() / len(prediction)\n",
    "    micro_f1 = f1_score(labels, prediction, average='micro')\n",
    "    macro_f1 = f1_score(labels, prediction, average='macro')\n",
    "\n",
    "    return accuracy, micro_f1, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5db100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, g, features, labels, mask, loss_func):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(g, features)\n",
    "    loss = loss_func(logits[mask], labels[mask])\n",
    "    accuracy, micro_f1, macro_f1 = score(logits[mask], labels[mask])\n",
    "\n",
    "    return loss, accuracy, micro_f1, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27cd9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    # If args['hetero'] is True, g would be a heterogeneous graph.\n",
    "    # Otherwise, it will be a list of homogeneous graphs.\n",
    "    g, features, labels, num_classes, train_idx, val_idx, test_idx, train_mask, \\\n",
    "    val_mask, test_mask = load_data(args['dataset'])\n",
    "\n",
    "    print('args dataset',args['dataset'])\n",
    "    if hasattr(torch, 'BoolTensor'):\n",
    "        train_mask = train_mask.bool()\n",
    "        val_mask = val_mask.bool()\n",
    "        test_mask = test_mask.bool()\n",
    "    \n",
    "    sampler = dgl.dataloading.MultiLayerNeighborSampler([\n",
    "    {('author', 'ai', 'institution'): 3,\n",
    "    ('institution', 'ia', 'author'): 3,\n",
    "    ('author', 'ap', 'paper'): 3,\n",
    "    ('paper', 'pa', 'author'): 3,\n",
    "    ('paper', 'pP', 'paper'): 3,\n",
    "    ('paper', 'Pp', 'paper'): 3,\n",
    "    ('paper', 'pf', 'field_of_study'): 3,\n",
    "    ('field_of_study', 'fp', 'paper'): 3}] * 3)\n",
    "    collator = dgl.dataloading.NodeCollator(g, train_idx, sampler)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "    collator.dataset, collate_fn=collator.collate,\n",
    "    batch_size=1024, shuffle=True, drop_last=False, num_workers=4)   \n",
    "\n",
    "    \"\"\"features = features.to(args['device'])\n",
    "    labels = labels.to(args['device'])\n",
    "    train_mask = train_mask.to(args['device'])\n",
    "    val_mask = val_mask.to(args['device'])\n",
    "    test_mask = test_mask.to(args['device'])\"\"\"\n",
    "\n",
    "    #meta_paths=[['pa', 'ap'], ['pf', 'fp']]\n",
    "    model = HAN(meta_paths=[['pa', 'ap'], ['pf', 'fp'], ['ai', 'ia'], ['pP', 'Pp']],\n",
    "                    in_size=features.shape[1],\n",
    "                    hidden_size=args['hidden_units'],\n",
    "                    out_size=num_classes,\n",
    "                    num_heads=args['num_heads'],\n",
    "                    dropout=args['dropout']).to(args['device'])\n",
    "    g = g.to(args['device'])\n",
    "   \n",
    "    stopper = EarlyStopping(patience=args['patience'])\n",
    "    loss_fcn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'],\n",
    "                                 weight_decay=args['weight_decay'])\n",
    "\n",
    "    for epoch in range(args['num_epochs']):\n",
    "        i=0\n",
    "        for input_nodes, output_nodes, blocks in dataloader:\n",
    "            #blocks = [b.to(torch.device('cpu')) for b in blocks]\n",
    "            #print(blocks[-1])\n",
    "            input_features = blocks[0].srcdata['features']\n",
    "            output_labels = blocks[-1].dstdata['labels']\n",
    "            #print(blocks)\n",
    "            model.train()\n",
    "            output_predictions = model(blocks, input_features)\n",
    "            loss = loss_fcn(output_labels, output_predictions)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_acc, train_micro_f1, train_macro_f1 = score(output_labels, output_predictions)\n",
    "            #val_loss, val_acc, val_micro_f1, val_macro_f1 = evaluate(model, blocks, input_features, output_labels, val_mask, loss_fcn)\n",
    "            #early_stop = stopper.step(val_loss.data.item(), val_acc, model)\n",
    "\n",
    "            print('Epoch {:d} | Epoch {:d} | Train Loss {:.4f} | Train Micro f1 {:.4f} | Train Macro f1 {:.4f} | '\n",
    "              .format(\n",
    "            epoch + 1, i+1, loss.item(), train_micro_f1, train_macro_f1))\n",
    "\n",
    "        #if early_stop:\n",
    "            #break\n",
    "\n",
    "    stopper.load_checkpoint(model)\n",
    "    test_loss, test_acc, test_micro_f1, test_macro_f1 = evaluate(model, g, features, labels, test_mask, loss_fcn)\n",
    "    print('Test loss {:.4f} | Test Micro f1 {:.4f} | Test Macro f1 {:.4f}'.format(\n",
    "        test_loss.item(), test_micro_f1, test_macro_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afa073ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3bccf5d019ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msetup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'HAN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "\n",
    "    from utils import setup\n",
    "\n",
    "    parser = argparse.ArgumentParser('HAN')\n",
    "    parser.add_argument('-s', '--seed', type=int, default=1,\n",
    "                        help='Random seed')\n",
    "    parser.add_argument('-ld', '--log-dir', type=str, default='results',\n",
    "                        help='Dir for saving training results')\n",
    "    parser.add_argument('--acmraw', action='store_true',\n",
    "                        help='Use metapath coalescing with DGL\\'s own dataset')\n",
    "    parser.add_argument('--mag', action='store_true',\n",
    "                        help='Use metapath coalescing with DGL\\'s own dataset')\n",
    "    args = parser.parse_args().__dict__\n",
    "\n",
    "    args = setup(args)\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe5e753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "from dgl.data.utils import load_graphs\n",
    "from ogb.nodeproppred import DglNodePropPredDataset\n",
    "from ogb.nodeproppred import Evaluator\n",
    "\n",
    "dataset = DglNodePropPredDataset(name = 'ogbn-mag')\n",
    "evaluator = Evaluator(name = 'ogbn-mag')\n",
    "\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "\n",
    "def node_level_subsampling(g, list_of_nodes, node_numbers):\n",
    "    subsample_data = {}\n",
    "    if len(list_of_nodes) == 0:\n",
    "        raise ValueError('list of nodes are empty')\n",
    "    \n",
    "    for node_type in list_of_nodes:\n",
    "        subsample_data[node_type]=g.nodes(node_type)[:node_numbers]\n",
    "    \n",
    "    return dgl.node_subgraph(g,subsample_data)\n",
    "    \n",
    "\n",
    "def create_mask_from_idx(idx,total_nodes):\n",
    "    mask_array = np.zeros(total_nodes,dtype=bool)\n",
    "    mask_array[idx]=True\n",
    "    return mask_array\n",
    "\n",
    "def load_mag_data():\n",
    "    graph = load_graphs('./mag_mp.bin')\n",
    "    _, label = dataset[0]\n",
    "    g = graph[0][0]\n",
    "    print(g)\n",
    "    features = g.ndata['feat']['paper']\n",
    "    labels = label['paper']\n",
    "    mask = torch.BoolTensor(create_mask_from_idx(train_idx['paper'], g.num_nodes('paper')))\n",
    "   \n",
    "    return g, features, labels, mask\n",
    "\n",
    "def prepare_accuracy_csv(model_name, train_acc, validation_acc, test_acc, total_epoch, total_duration, timestamp):\n",
    "    accuracy_csv_data = []\n",
    "    accuracy_csv_data.append([str(model_name),str(train_acc),str(validation_acc), str(test_acc), str(total_epoch), str(total_duration), str(timestamp)])\n",
    "    return accuracy_csv_data\n",
    "\n",
    "def write_csv(file_name, columns_name, data):\n",
    "    df_csv = pd.DataFrame(data, columns = columns_name)\n",
    "    if not os.path.isfile(file_name):\n",
    "       df_csv.to_csv(file_name, header='column_names')\n",
    "    else: # else it exists so append without writing the header\n",
    "       df_csv.to_csv(file_name, header=False, mode='a')\n",
    "    \n",
    "def prepare_epoch_csv(epoch_number, current_loss, total_duration, timestamp):\n",
    "    epoch_csv_data = []\n",
    "    epoch_csv_data.append([str(epoch_number),str(current_loss), str(total_duration), str(timestamp)])\n",
    "    return epoch_csv_data    \n",
    "\n",
    "def test_accuracy_HeteroRGCN(model, x_dict, y_true, split_idx, evaluator):\n",
    "    model.eval()\n",
    "\n",
    "    out = model(x_dict)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['train']['paper']],\n",
    "        'y_pred': y_pred[split_idx['train']['paper']],\n",
    "    })['acc']\n",
    "    valid_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['valid']['paper']],\n",
    "        'y_pred': y_pred[split_idx['valid']['paper']],\n",
    "    })['acc']\n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['test']['paper']],\n",
    "        'y_pred': y_pred[split_idx['test']['paper']],\n",
    "    })['acc']\n",
    "\n",
    "    return train_acc, valid_acc, test_acc\n",
    "\n",
    "def test_accuracy_RGCN(model, x_dict, adj_t_dict, y_true, split_idx, evaluator):\n",
    "    model.eval()\n",
    "\n",
    "    out = model(x_dict, adj_t_dict)['paper']\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['train']['paper']],\n",
    "        'y_pred': y_pred[split_idx['train']['paper']],\n",
    "    })['acc']\n",
    "    valid_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['valid']['paper']],\n",
    "        'y_pred': y_pred[split_idx['valid']['paper']],\n",
    "    })['acc']\n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['test']['paper']],\n",
    "        'y_pred': y_pred[split_idx['test']['paper']],\n",
    "    })['acc']\n",
    "\n",
    "    return train_acc, valid_acc, test_acc\n",
    "\n",
    "accuracy_columns = ['Model_Name','Train_Acc', 'Validation_Acc', 'Test_Acc', 'Total_Epoch', 'Total_Duration','TimeStamp']\n",
    "epoch_columns = ['Epoch_No', 'NLL_loss', 'Total_Duration','TimeStamp']\n",
    "modelaccuracy_file_name = 'modelaccuracy.csv'\n",
    "epoch_file_name = 'epochdetails.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Heterograph Conv model\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(in_feats, hid_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "        self.conv2 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(hid_feats, out_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # inputs are features of nodes\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = {k: F.relu(v) for k, v in h.items()}\n",
    "        h = self.conv2(graph, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Heterograph Conv model\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "\n",
    "class HeteroRGCNLayer(nn.Module):\n",
    "    def __init__(self, in_size, out_size, etypes):\n",
    "        super(HeteroRGCNLayer, self).__init__()\n",
    "        # W_r for each relation\n",
    "        self.weight = nn.ModuleDict({\n",
    "                name : nn.Linear(in_size, out_size) for name in etypes\n",
    "            })\n",
    "\n",
    "    def forward(self, G, feat_dict):\n",
    "        # The input is a dictionary of node features for each type\n",
    "        funcs = {}\n",
    "        for srctype, etype, dsttype in G.canonical_etypes:\n",
    "            # Compute W_r * h\n",
    "            Wh = self.weight[etype](feat_dict[srctype])\n",
    "            # Save it in graph for message passing\n",
    "            G.nodes[srctype].data['Wh_%s' % etype] = Wh\n",
    "            # Specify per-relation message passing functions: (message_func, reduce_func).\n",
    "            # Note that the results are saved to the same destination feature 'h', which\n",
    "            # hints the type wise reducer for aggregation.\n",
    "            funcs[etype] = (fn.copy_u('Wh_%s' % etype, 'm'), fn.mean('m', 'h'))\n",
    "        # Trigger message passing of multiple types.\n",
    "        # The first argument is the message passing functions for each relation.\n",
    "        # The second one is the type wise reducer, could be \"sum\", \"max\",\n",
    "        # \"min\", \"mean\", \"stack\"\n",
    "        G.multi_update_all(funcs, 'sum')\n",
    "        # return the updated node feature dictionary\n",
    "        return {ntype : G.nodes[ntype].data['h'] for ntype in G.ntypes}\n",
    "\n",
    "class HeteroRGCN(nn.Module):\n",
    "    def __init__(self, G, in_size, hidden_size, out_size):\n",
    "        super(HeteroRGCN, self).__init__()\n",
    "        # Use trainable node embeddings as featureless inputs.\n",
    "        embed_dict = {ntype : nn.Parameter(torch.Tensor(G.number_of_nodes(ntype), in_size))\n",
    "                      for ntype in G.ntypes}\n",
    "        for key, embed in embed_dict.items():\n",
    "            nn.init.xavier_uniform_(embed)\n",
    "        self.embed = nn.ParameterDict(embed_dict)\n",
    "        # create layers\n",
    "        self.layer1 = HeteroRGCNLayer(in_size, hidden_size, G.etypes)\n",
    "        self.layer2 = HeteroRGCNLayer(hidden_size, out_size, G.etypes)\n",
    "\n",
    "    def forward(self, G):\n",
    "        h_dict = self.layer1(G, self.embed)\n",
    "        h_dict = {k : F.leaky_relu(h) for k, h in h_dict.items()}\n",
    "        h_dict = self.layer2(G, h_dict)\n",
    "        # get paper logits\n",
    "        return h_dict['paper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(model_name):\n",
    "    g, features, labels, mask = load_mag_data()\n",
    "    if model_name.upper() == 'HETERORGCN':\n",
    "        model = HeteroRGCN(g, 128, 20, 349)\n",
    "    elif model_name.upper() == 'RGCN':\n",
    "        model = RGCN(128, 20, 349,g.etypes)\n",
    "\n",
    "    \n",
    "    paper_feats = features\n",
    "    author_feats = torch.zeros([g.num_nodes('author'), 128])\n",
    "    fos_feats = torch.zeros([g.num_nodes('field_of_study'), 128])\n",
    "    institute_feats = torch.zeros([g.num_nodes('institution'), 128])\n",
    "    train_mask = mask\n",
    "    node_features = {'paper': paper_feats, 'author':author_feats, 'field_of_study':fos_feats, 'institution': institute_feats}\n",
    "    return g, labels, node_features, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare_model('HeteroRGCN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes={'author': 1134649, 'field_of_study': 59965, 'institution': 8740, 'paper': 736389},\n",
      "      num_edges={('author', 'ai', 'institution'): 1043998, ('author', 'ap', 'paper'): 7145660, ('field_of_study', 'fp', 'paper'): 7505078, ('institution', 'ia', 'author'): 1043998, ('paper', 'pa', 'author'): 7145660, ('paper', 'pf', 'field_of_study'): 7505078, ('paper', 'pp', 'paper'): 5416271},\n",
      "      metagraph=[('author', 'institution', 'ai'), ('author', 'paper', 'ap'), ('institution', 'author', 'ia'), ('paper', 'author', 'pa'), ('paper', 'field_of_study', 'pf'), ('paper', 'paper', 'pp'), ('field_of_study', 'paper', 'fp')])\n",
      "torch.Size([736389, 128])\n",
      "torch.Size([1134649, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ai', 'ap', 'fp', 'ia', 'pa', 'pf', 'pp']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g, features, labels, mask = load_mag_data()\n",
    "h_model = HeteroRGCN(g, 128, 20, 349)\n",
    "r_model = RGCN(128, 20, 349,g.etypes)\n",
    "paper_feats = features\n",
    "author_feats = torch.zeros([g.num_nodes('author'), 128])\n",
    "fos_feats = torch.zeros([g.num_nodes('field_of_study'), 128])\n",
    "institute_feats = torch.zeros([g.num_nodes('institution'), 128])\n",
    "train_mask = mask\n",
    "print(paper_feats.shape)\n",
    "print(author_feats.shape)\n",
    "node_features = {'paper': paper_feats, 'author':author_feats, 'field_of_study':fos_feats, 'institution': institute_feats}\n",
    "g.etypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(total_epoch, model_name):  \n",
    "    if model_name.upper() == 'HETERORGCN':\n",
    "        model = h_model\n",
    "    elif model_name.upper() == 'RGCN':\n",
    "        model = r_model\n",
    "    else: \n",
    "        raise ValueError('Model Name is not recognized')\n",
    "    start_time = datetime.datetime.now().replace(microsecond=0)\n",
    "    now = datetime.datetime.now() # current date and time\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=5e-4)\n",
    "    current_date_time = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    epoch_file_name = \"Training_Epoch_(\" + model_name + \")_\" + str(total_epoch) + \"__\" + current_date_time + \".csv\"\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "    for epoch in range(total_epoch):\n",
    "        epoch_start_time = datetime.datetime.now().replace(microsecond=0)\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "        if model_name.upper() == 'HETERORGCN':\n",
    "            logits = model(g)\n",
    "            pred = logits.argmax(1)\n",
    "        elif model_name.upper() == 'RGCN':\n",
    "            logits = model(g, node_features)['paper'].log_softmax(dim=-1)\n",
    "            y_pred = logits.argmax(dim=-1, keepdim=True)    \n",
    "        loss = F.cross_entropy(logits[train_idx['paper']], labels[train_idx['paper']].squeeze())\n",
    "        print(\"Loss :\", loss.item())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        current_time = datetime.datetime.now().replace(microsecond=0)\n",
    "        print(\"Epoch Completed : \", epoch, \"         Current Time: \", current_time)\n",
    "        epoch_end_time = datetime.datetime.now().replace(microsecond=0)\n",
    "        total_epoch_time = epoch_end_time - epoch_start_time\n",
    "        data_epoch = prepare_epoch_csv(epoch, loss.item(), total_epoch_time, epoch_end_time)\n",
    "        write_csv(epoch_file_name, epoch_columns, data_epoch)\n",
    "    \n",
    "    if model_name.upper() == 'HETERORGCN':\n",
    "        train_acc, valid_acc, test_acc = test_accuracy_HeteroRGCN(model, g, labels, split_idx, evaluator)\n",
    "    elif model_name.upper() == 'RGCN':\n",
    "        train_acc, valid_acc, test_acc =  test_accuracy_RGCN(model, g, node_features, labels, split_idx, evaluator)\n",
    "    end_time = datetime.datetime.now().replace(microsecond=0)\n",
    "    total_time = end_time - start_time\n",
    "    print (\"Train_Acc :\", train_acc)\n",
    "    print (\"Validation_Acc :\",valid_acc)\n",
    "    print (\"Test_Acc :\",test_acc)\n",
    "    data_accuracy = prepare_accuracy_csv(model_name,train_acc, valid_acc, test_acc, total_epoch, total_time, end_time)\n",
    "    write_csv(modelaccuracy_file_name, accuracy_columns, data_accuracy)\n",
    "    print (\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 3.4757847785949707\n",
      "Epoch Completed :  0          Current Time:  2021-06-20 17:54:41\n",
      "Loss : 4.850241661071777\n",
      "Epoch Completed :  1          Current Time:  2021-06-20 17:54:55\n",
      "Loss : 4.101527690887451\n",
      "Epoch Completed :  2          Current Time:  2021-06-20 17:55:10\n",
      "Loss : 3.8440663814544678\n",
      "Epoch Completed :  3          Current Time:  2021-06-20 17:55:24\n",
      "Loss : 3.8339908123016357\n",
      "Epoch Completed :  4          Current Time:  2021-06-20 17:55:38\n",
      "Loss : 3.7999181747436523\n",
      "Epoch Completed :  5          Current Time:  2021-06-20 17:55:52\n"
     ]
    }
   ],
   "source": [
    "#run_experiment(25, 'HeteroRGCN')\n",
    "run_experiment(100, 'RGCN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.is_available()\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
